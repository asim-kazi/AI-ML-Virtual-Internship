{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Hkwa1MJYxySC"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to your image files\n",
        "image_files = [\n",
        "    'cat.0.jpg', 'cat.1.jpg', 'cat.2.jpg', 'cat.3.jpg',\n",
        "    'dog.0.jpg', 'dog.1.jpg', 'dog.2.jpg', 'dog.3.jpg'\n",
        "]\n",
        "\n",
        "# Define the labels for your images (0 for cat, 1 for dog)\n",
        "labels = [0, 0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "def load_and_preprocess_image(file_path, image_size=(180, 180)):\n",
        "    \"\"\"Loads and preprocesses a single image.\"\"\"\n",
        "    img = tf.keras.preprocessing.image.load_img(file_path, target_size=image_size)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return img_array\n",
        "\n",
        "# Load and preprocess all images\n",
        "images = [load_and_preprocess_image(file_path) for file_path in image_files]\n",
        "images = np.array(images) # Convert to numpy array\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=123)\n",
        "\n",
        "# Convert labels to categorical format (one-hot encoding)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
        "\n",
        "# Create TensorFlow datasets from the NumPy arrays\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)"
      ],
      "metadata": {
        "id": "sSCXBG9Nx7Oq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')  # 2 output classes: cat and dog\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwbJvWiFyG87",
        "outputId": "ffd59bc9-cdcb-4817-f9f0-a95f42953cdd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy', # Use categorical_crossentropy for one-hot encoded labels\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_dataset, epochs=5, validation_data=validation_dataset) # Use the tf.data.Dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQHdiMlV4BUq",
        "outputId": "a7790ad5-cd7e-4ee2-81de-e15e71dfbd22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.6950 - val_accuracy: 0.0000e+00 - val_loss: 23.4280\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849ms/step - accuracy: 0.6667 - loss: 11.5319 - val_accuracy: 0.0000e+00 - val_loss: 6.0797\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825ms/step - accuracy: 0.6667 - loss: 2.4005 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - accuracy: 0.3333 - loss: 3.5104 - val_accuracy: 1.0000 - val_loss: 0.0733\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.3333 - loss: 1.9710 - val_accuracy: 1.0000 - val_loss: 0.4696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load your image\n",
        "img = image.load_img('dog.105.jpg', target_size=(180, 180))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Batch dimension\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(img_array)\n",
        "print(\"Prediction: \", \"Dog\" if pred[0][0] > 0.5 else \"Cat\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv45D78P4ENe",
        "outputId": "764b1d18-562e-4e0d-8ddf-033879b2fe75"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "Prediction:  Dog\n"
          ]
        }
      ]
    }
  ]
}